{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t5-small v3\n",
    "## following set ups at AT2_NLP_Pipeline.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is avalible\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up cache\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate packages\n",
    "## to import data\n",
    "import os\n",
    "import pickle\n",
    "from datasets import load_dataset, DatasetDict, concatenate_datasets\n",
    "\n",
    "## for data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "## for NLP pre-procssing\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, T5Config\n",
    "from transformers import Trainer, TrainingArguments, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "import nltk\n",
    "\n",
    "import evaluate\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global variables\n",
    "localfolderpath = 'C:/Users/TinaM/Desktop/TMB_File/UTS_AUT_2023/36118_ANLP/AT2'\n",
    "gitfolderpath = 'C:/Users/TinaM/Desktop/TMB_File/UTS_AUT_2023/36118_ANLP/AT2/GitHubFolder/TLDR'\n",
    "rawdata_folder = localfolderpath + '/dataset/'\n",
    "model_name=\"t5-small\"\n",
    "ver_='_v4_adam_full'\n",
    "wk_dir = os.path.join(localfolderpath, f\"{model_name}{ver_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Path: c:\\Users\\TinaM\\Desktop\\TMB_File\\UTS_AUT_2023\\36118_ANLP\\AT2\\GitHubFolder\n",
      "Current working path is: C:\\Users\\TinaM\\Desktop\\TMB_File\\UTS_AUT_2023\\36118_ANLP\\AT2\\t5-small_v4_adam_full\n"
     ]
    }
   ],
   "source": [
    "print(f'Default Path: {os.getcwd()}')\n",
    "\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(wk_dir)\n",
    "if not isExist:\n",
    "\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(wk_dir)\n",
    "\n",
    "os.chdir(wk_dir)\n",
    "print(f'Current working path is: {os.getcwd()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset multi_news (C:/Users/TinaM/.cache/huggingface/datasets/multi_news/default/1.0.0/2f1f69a2bedc8ad1c5d8ae5148e4755ee7095f465c1c01ae8f85454342065a72)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25279b842df94a4787cfe456bc5e5e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import raw data\n",
    "ds_raw = load_dataset(\"multi_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into smaller subset for initial training\n",
    "def split_dataset(dataset, percentage):\n",
    "    train_set = dataset['train'].train_test_split(test_size=percentage)['train']\n",
    "    test_set = dataset['test'].train_test_split(test_size=percentage)['train']\n",
    "    validation_set = dataset['validation'].train_test_split(test_size=percentage)['train']\n",
    "    \n",
    "    return DatasetDict({'train': train_set, 'test': test_set, 'validation': validation_set})\n",
    "\n",
    "# use the full dataset: split_percentage = 1\n",
    "split_percentage = 1\n",
    "\n",
    "ds = split_dataset(ds_raw, split_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Size of the dataset:\n",
      "      The train raw data full set has 44972 rows, with 2 columns.\n",
      "      The train dataset to use has has 44971 rows, with 2 columns.\n",
      "      The test raw data full set has 5622 rows, with 2 columns.\n",
      "      The test dataset to use has has 5621 rows, with 2 columns.\n",
      "      The validation raw data full set has 5622 rows, with 2 columns.\n",
      "      The validation dataset to use has has 5621 rows, with 2 columns.\n",
      "       \n"
     ]
    }
   ],
   "source": [
    "# dataset len\n",
    "print(f\"\\\n",
    "     Size of the dataset:\\n \\\n",
    "     The train raw data full set has {len(ds_raw['train'])} rows, with {ds_raw['train'].shape[1]} columns.\\n \\\n",
    "     The train dataset to use has has {len(ds['train'])} rows, with {ds['train'].shape[1]} columns.\\n \\\n",
    "     The test raw data full set has {len(ds_raw['test'])} rows, with {ds_raw['test'].shape[1]} columns.\\n \\\n",
    "     The test dataset to use has has {len(ds['test'])} rows, with {ds['test'].shape[1]} columns.\\n \\\n",
    "     The validation raw data full set has {len(ds_raw['validation'])} rows, with {ds_raw['validation'].shape[1]} columns.\\n \\\n",
    "     The validation dataset to use has has {len(ds['validation'])} rows, with {ds['validation'].shape[1]} columns.\\n \\\n",
    "      \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of train data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'document': 'The Sundance Film Festival is where the road to the Oscars begins. Check out these Academy Award-winners that played at Sundance. How many have you seen? \\n \\n Check out the full list ||||| Getty Images \\n \\n Charlie Sheen appears in the upcoming Robert Rodriguez film \"Machete Kills,\" he\\'s just not using the name Charlie Sheen. According to TMZ, Sheen is credited in \"Machete Kills\" with his birth name, Carlos Estevez. \\n \\n Sheen has said in the past that he took the name Charlie when he was a kid to avoid confusion with an uncle who was also named Carlos. Sheen\\'s father, Martin Sheen, was born with the name Ramon Antonio Gerardo Estevez; according to the New York Times, the 72-year-old acting legend took the stage name of Sheen as a tribute to Bishop Fulton J. Sheen. He also hoped it would get him more acting parts. Sheen never legally changed his name, however, and passed the Estevez name down to his four children, including to his son, actor Emilio Estevez. \\n \\n \"I started using Sheen, I thought I\\'d give it a try, and before I knew it, I started making a living with it and then it was too late,\" Martin Sheen told James Lipton on an episode of \"Inside the Actors Studio.\" \"In fact, one of my great regrets is that I didn\\'t keep my name as it was given to me. I knew it bothered my dad.\" \\n \\n Sheen/Estevez included, the \"Machete Kills\" cast could only be described as cuckoo bananas. Sofia Vergara, Mel Gibson, Vanessa Hudgens, Cuba Gooding Jr. and Lady Gaga all star. Danny Trejo plays the title Machete, but its Sheen who may have the best role: He\\'s reportedly playing the President of the United States. \\n \\n For a look at Sheen in \"Machete Kills,\" head to TMZ. \"Machete Kills\" is out on Sept. 13. \\n \\n [via TMZ]',\n",
       " 'summary': \"– This could be a bit of a headache for IMDb: When Charlie Sheen appears in the upcoming movie Machete Kills, he won't be Charlie Sheen. Instead he will be billed as Carlos Estevez—marking the first time in his acting career that Sheen will use his birth name, reports TMZ. (Dad Martin Sheen was born Ramon Antonio Gerardo Estevez, and brother Emilio has always used his real last name, notes the Huffington Post.) The move is presumed to be a temporary one, and TMZ speculates that Sheen is celebrating his Latino roots in the spirit of the Robert Rodriguez film.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Sample of train data:')\n",
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of test data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'document': '(CNN) A police officer who claimed she killed a Dallas man in his own apartment in the mistaken belief that he was in her home was indicted Friday on a murder charge, authorities said. \\n \\n The indictment of Amber Guyger comes more than two months after she was arrested in the shooting death of Botham Shem Jean at the Dallas apartment complex where both lived -- a killing that sparked days of protests. \\n \\n Guyger was arrested after the September shooting and charged with manslaughter by the Texas Rangers, the lead investigative agency, Dallas County District Attorney Faith Johnson said at a news conference. \\n \\n When asked why the grand jury indicted Guyger on the more serious offense of murder, Johnson replied, \"We presented the evidence and we explained the law.\" \\n \\n Johnson said murder constitutes someone \"intentionally and knowingly\" committing a crime, whereas manslaughter involves \"recklessly doing something.\" \\n \\n \"At the moment of the shooting it was a knowing ... offense,\" Johnson said. \\n \\n The court records Friday showed both a manslaughter and murder charge entered in Guyger\\'s file, but a clerk of court clerk confirmed that the murder charge is the one prosecutors are moving forward on. \\n \\n Robert Rogers, Guyger\\'s attorney, was disappointed but not surprised by the indictment, given what he called an \"outpouring of vindictive emotion\" in a statement late Friday. \\n \\n \"This is a terrible tragedy that resulted from a true mistake,\" he said. \"We are confident that a dispassionate jury in a fair forum will objectively apply the law to the facts and find Amber not guilty.\" \\n \\n Guyger had already been arrested again and released on bond, Johnson said at the news conference. \\n \\n Dallas Police Chief U. Reneè Hall said in a statement everyone in the department \"continues to feel anguish about this difficult and tragic event.\" \\n \\n \"We recognize and understand the national discord regarding the relationship between law enforcement and the communities we serve,\" Hall said. \\n \\n She also added that the department has \"developed a framework for policy change\" by restructuring the Citizen Review Board, revamping implicit bias training and seeking input from employee advisory and community advisory boards. \\n \\n \"We have more work to do and we remain committed to improving our relationships throughout the city,\" Hall said. \\n \\n The indictment is a \"step toward justice\" for Jean\\'s family, said Sharon Watkins Jones, ACLU of Texas Director of Political Strategies. \\n \\n \"The Jean family\\'s loss cannot be restored to them, but we will continue to work to ensure that police officers are held to the same standards as everyone else in the Dallas community and across the state of Texas,\" she said. \\n \\n \\'He didn\\'t deserve it,\" Jean\\'s mother says \\n \\n Botham Jean\\'s mother, Allison Jean, said during a news conference that she\\'s satisfied with the murder indictment. \\n \\n Guyger \"inflicted tremendous evil on my son,\" Allison Jean said. \"He didn\\'t deserve it. He was seated in his own apartment. He felt safe and he was violated by her coming in and murdering him,\" she said. \\n \\n Allison said she hopes a proper penalty will cause Guyger to reflect on what she has allegedly done and the pain she has caused. \\n \\n Family attorney S. Lee Merritt said the grand jury decision is \"groundbreaking, but it is also just a start.\" \\n \\n Officer thought she was in her own apartment, warrant says \\n \\n Guyger, who is white, was off-duty when she encountered Jean , an 26-year-old unarmed black man, in his apartment on September 6, police said. Still in her uniform, Guyger parked her car in the complex and walked to what she believed was her apartment, according to an arrest warrant affidavit \\n \\n The door was slightly ajar as she tried to use her key, which has an electronic chip. When she opened the door, she saw the interior was almost completely dark, according to the affidavit. She described seeing a large silhouette and, believing there was an intruder in her apartment, drew her firearm. \\n \\n Amber Guyger is charged with killing Botham Shem Jean on September 6. \\n \\n She issued verbal commands, but Jean, being in his own home, did not heed them, and Guyger fired two shots, hitting him once in the torso, the affidavit said. \\n \\n Guyger, a four-year veteran, then entered the apartment, called 911 and started administering first aid to Jean. She turned on the lights while on the phone with 911, and only when asked for her address did she realize she was in the wrong apartment, she told police. \\n \\n Jean died at a hospital. Guyger was arrested September 9 on suspicion on manslaughter, and was released from the Kaufman County Jail after posting a $300,000 bond. \\n \\n The Dallas Police Department fired Guyger during a hearing September 24, the police chief said. \\n \\n Johnson will not prosecute the case. She was defeated in the November election by John Creuzo t, who will take office in January. \\n \\n JUST WATCHED CNN was granted access to Botham Jean\\'s apartment Replay More Videos ... MUST WATCH CNN was granted access to Botham Jean\\'s apartment 03:30 \\n \\n The shooting sparked days of protest . Police deployed pepper balls on demonstrators a week after the shooting. Protesters angry with the lack of public information in the case interrupted a City Council meeting to demand accountability and more police oversight in general. \\n \\n Jean\\'s parents filed a lawsuit in federal court against Guyger and the city last month, alleging Guyger used excessive force. \\n \\n Correction: An earlier version of this article said that Guyger was indicted on a charge of manslaughter. The officer has been indicted on a murder charge. The headline and article have been updated to reflect this change. ||||| A former Dallas police officer who walked into an unarmed man’s apartment on Sept. 6 and shot him while wearing her police uniform has been indicted on a charge of murder. \\n \\n The Dallas County grand jury began hearing the case against Amber Guyger, 30, on Monday. Guyger was originally charged with manslaughter in the shooting death of 26-year-old Botham Shem Jean. She was released from jail on a $300,000 bond about an hour after turning herself in. \\n \\n District Attorney Faith Johnson said that by 3 p.m., Guyger had turned herself back in on the murder charge. Her bond was transferred and she has been released. \\n \\n Asked why the grand jury indicted Guyger on a murder charge, Johnson said, “We presented the evidence and explained the law.” She added that the law prohibits her from talking about the evidence presented to the grand jury. \\n \\n Premium content for only $0.99 For the most comprehensive local coverage, subscribe today. \\n \\n She said her office had a “very spirited conversation” with the Texas Rangers, the lead investigators in the case, back in September. \\n \\n “They chose to file this case as manslaughter,” she said. “We did our own investigation.” \\n \\n She said that prosecutors talked to more than 300 witnesses. \\n \\n Guyger has said she mistook Jean’s apartment at the South Side Flats for hers that night after getting off a long work shift, Dallas police said. Court documents have varied on the story of how Guyger got Jean’s door open. \\n \\n FILE - This file photo provided by the Kaufman County Sheriff’s Office shows Amber Guyger. A grand jury began hearing evidence Monday, Nov. 26, 2018, in the case of Guyger, a former Dallas police officer who fatally shot her unarmed black neighbor in his own apartment after she said she mistook it for hers on Sept. 6, 2018. (Kaufman County (Texas) Sheriff’s Office via AP, File) AP \\n \\n Johnson said that at the moment of the shooting, the action was intentional. She was not able to speak about what Guyger was thinking or doing before the shooting. \\n \\n For a charge of murder, prosecutors have to prove without a reasonable doubt that Guyger intended to kill Jean. \\n \\n Court documents have said that Guyger says she believed Jean was an intruder in her own apartment. \\n \\n The Star-Telegram, along with several other media outlets, have requested copies of the 911 call Guyger made after the shooting, along with body camera footage worn by the officers who responded. The Dallas Police Department has declined to release that information and sent the open records requests to the attorney general for final determination. \\n \\n Guyger was not wearing a body camera. The department said officers leave their body cameras at work after their shift. \\n \\n Johnson, who was voted out of office in the Nov. 6 election, will not see the case through to a trial and said Friday that she “trusts the DA-elect will continue to represent this family (and all of Dallas County) as he seeks justice for victims.” \\n \\n Johnson also spoke about why it took her office two months to bring the case in front of a grand jury. She said she wanted to make sure the jurors had everything they needed to “make the right choice.” \\n \\n “We thought it was murder all along,” she said. “But we didn’t file this case ... we did what we had to to get this case ready for the grand jury. Justice is never too long.” \\n \\n Moving forward, it could be more than a year before Guyger sits in front of a judge and jury. It took 16 months, Johnson said, for the case against Roy Oliver to go to trial. Oliver shot and killed 15-year-old Jordan Edwards while on duty as a Balch Springs police officer. He was found guilty of murder. \\n \\n Guyger was fired from the Dallas Police Department on Sept. 24. On Friday, Police Chief U. Renee Hall released a statement saying every person in the department continues to “feel anguish about this difficult and tragic event that occurred.” \\n \\n “We have developed the framework for policy change, have supported the restructuring of the Citizen Review Board, pushed to exceed the basic requirements of implicit bias training, and have relied on input from our employee advisory and community advisory boards,” she said. “We have more work to do and we remain committed to improving our relationships throughout the city.” \\n \\n \\n \\n \\n \\n The Lawyers’ Committee for Civil Rights Under Law said the indictment is an “important reminder that police derive their authority from the people and it is the people, functioning as members of grand juries, who must insist that police authority be exercised in a lawful manner and who must hold police accountable when they fail to do so.” \\n \\n Jean was a native of the Caribbean island of St. Lucia. After graduating from college in Arkansas, he moved to Dallas to work for PriceWaterHouseCoopers. \\n \\n Jean’s family filed a lawsuit against the City of Dallas and its police department in late October. \\n \\n Jean’s family says in the suit that Guyger had a history of violence and used excessive force against Jean that fateful night in September, resulting in his wrongful death. \\n \\n The family also says the Dallas Police Department “has a pattern, practice, history, and custom of using excessive force against minorities,” and accuses it of not providing proper training or discipline for Guyger in the use of deadly force. \\n \\n “By simply following proper police procedures and the best police practices and not the protocol of the DPD to ‘shoot first and ask questions later,’ Defendant Guyger would have not shot Jean,” the lawsuit states. “Essentially, Officer Guyger was ill-trained, and as a result, defaulted to the defective DPD policy: to use deadly force even when there exists no immediate threat of harm to themselves or others.” \\n \\n SHARE COPY LINK The parents of Botham Jean — Allison and Bertrum Jean — sat down with the Star-Telegram on Oct. 17 to talk about their son, who was killed by an off-duty, uniformed Dallas police officer on Sept. 6.',\n",
       " 'summary': '– In September, Amber Guyger, at that time a Dallas police officer, walked into the apartment of Botham Shem Jean and shot the 26-year-old to death. Guyger lived in the same building as Jean and claimed that she thought she was entering her own unit and believed he was an intruder. On Friday, a grand jury indicted Guyger on a murder charge, CNN reports. Texas Rangers had initially arrested Guyger on a manslaughter charge. But Dallas County DA Faith Johnson said at a news conference, the grand jury settled on the more serious charge after “we presented the evidence and we explained the law.” The Texas Rangers “chose to file this case as manslaughter,” she said, per the Star-Telegram. “We did our own investigation. We thought it was murder all along.” Johnson said that murder involves causing a death “intentionally and knowingly,” as opposed to manslaughter, which results from recklessness. “At the moment of the shooting it was a knowing … offense,” she said per CNN. Jean, who was a native of St. Lucia in the Caribbean, went to college in Arkansas before moving to Dallas to work for PriceWaterHouseCoopers. His family filed a lawsuit against the city and police department in October. (This officer was fired for not shooting someone.)'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Sample of test data:')\n",
    "ds['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of validation data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'document': 'Black Sam Bellamy became the wealthiest pirate in history not because of greed but because of anger – anger at the English system that exploited poor country boys and sailors like him. \\n \\n After his early death in 1717 he left a legacy of folklore on Cape Cod and a ship loaded with treasure off its coast. In 1984, treasure hunters found his ship and in 2018 archaeologists believed they found his remains. \\n \\n Black Sam Bellamy ran his pirate operation democratically. His men were slaves and Indians and sailors pressed into service. Bellamy treated them equally and let them vote on important decisions. \\n \\n In a famous speech attributed to Bellamy, he scorned the wealthy merchants he plundered: “They rob the poor under the cover of law, forsooth, and we plunder the rich under the protection of our own courage.” \\n \\n Pirate historians have traced Bellamy\\'s career, summarized by Colin Woodard as \\'Fight smart, harm few, score big.\\' \\n \\n Robin Hood of the Sea \\n \\n Bellamy and his crew captured 53 ships before he died in a shipwreck at 28. They called him Black Sam Bellamy because he eschewed the fashion for powdered wigs and wore his black hair tied with a black satin bow. He had good manners, dressed neatly in fancy clothes, and he always wore four ornate dueling pistols in his sash. \\n \\n Black Sam Bellamy called himself ‘Robin Hood of the Sea,’ and his men called themselves ‘Robin Hood’s men.’ There is no record of him ever killing a captive, and he often returned captured ships and cargo if they didn’t suit his purpose. \\n \\n We know little of Black Sam Bellamy’s early life, though he is presumed to have been born in Devon in the west of England. The woman who was probably his mother died in childbirth and was buried Feb. 23, 1689. His parents were likely tenant farmers, hovering on the edge of starvation like half of England. \\n \\n Bellamy left home at a young age for a port – London, Bristol or Plymouth. He became a ship’s boy at 13 at the outset of the War of Spanish Succession. By the end of the war in 1712 he was a skilled sailor. \\n \\n Turn to Piracy \\n \\n No one knows how Black Sam Bellamy ended up on board a British ship. He may have been grabbed by a press gang. In the early 18th century, Britain didn’t have anywhere near enough sailors. The press gangs tricked country boys into signing up or simply kidnapped and forced on board ships. \\n \\n Once in service, ship captains routinely cheated sailors of their wages. They gave the sailors vague IOUs instead of wages, or paid them for their last voyage just before they left port for the next. Sometimes they simply didn\\'t pay them at all. \\n \\n Black Sam Bellamy sailed to Cape Cod in 1714 or early 1715 to seek his fortune, arriving in Eastham where he may have had relatives. There he had an affair with the beautiful Maria Hallett, all of 15. After impregnating Maria he sailed to Florida to recover Spanish treasure with his friend from Rhode Island, Paulsgrave Williams. Others got to the treasure first. \\n \\n The two men turned to piracy under Benjamin Hornigold, but the crew mutinied and elected Bellamy as their captain. \\n \\n Hen-hearted Numbskulls \\n \\n In 1717 Bellamy and his crew captured the Whydah Gally, a slave ship he refitted as a flagship with 28 guns. The Whydah had an advanced weapons system capable of attacking any man-of-war in the Americas. In a year, Black Sam Bellamy and his crew raided 54 ships along the U.S. East Coast and the Caribbean. All in all they captured treasure worth $120 million today, according to Forbes magazine. That made him the top-earning pirate. \\n \\n The Whydah Gally also captured a sloop under the command of a Capt. Beers. Black Sam Bellamy wanted to let him keep his ship, but his crew had voted to burn it. Bellamy asked the captain to join the pirates, and Beers declined. That inspired Bellamy’s famous speech: \\n \\n I am sorry they won\\'t let you have your sloop again, for I scorn to do any one a mischief, when it is not to my advantage; damn the sloop, we must sink her, and she might be of use to you. Though you are a sneaking puppy, and so are all those who will submit to be governed by laws which rich men have made for their own security; for the cowardly whelps have not the courage otherwise to defend what they get by knavery; but damn ye altogether: damn them for a pack of crafty rascals, and you, who serve them, for a parcel of hen-hearted numbskulls. They vilify us, the scoundrels do, when there is only this difference, they rob the poor under the cover of law, forsooth, and we plunder the rich under the protection of our own courage. Had you not better make then one of us, than sneak after these villains for employment? \\n \\n Black Sam Bellamy Lost and Found \\n \\n The Whydah and the Mary Anne, commanded by Williams, headed north to New England. Williams and the Mary Anne broke off to Rhode Island, where he wanted to visit his family. Bellamy continued on, perhaps to Eastham to see Maria, but the Whydah was shipwrecked off the coast of Wellfleet in a terrific Nor’easter on April 26, 1717. Black Sam Bellamy and all but two of the 142 men on board drowned. \\n \\n Eventually, 102 of the bodies from the Whydah Gally were buried in a mass grave. The Mary Anne was shipwrecked a few days later, leaving seven survivors. \\n \\n In 1984, underwater explorer Barry Clifford rediscovered the Whydah in 14 feet of water and five of sand. The Whydah’s artifacts can be seen at Expedition Whydah Sea-Lab & Learning Center in Provincetown, Mass. \\n \\n Since Clifford found the wreck of the Whydah, archaeologists continued to search the site. In 2018 they announced they may have found the remains of Black Sam Bellamy himself. \\n \\n Legacies \\n \\n The U.K. Telegraph reported scientists found a femur encased in a mass of iron, stone, silver, gold, tools and weapons. They found pieces of a crushed helmet, indicating a violent death. And they discovered an ornate pistol wrapped in a ribbon that probably belonged to Black Sam Bellamy. \\n \\n In 2016, an Englishman from Devon came to the Whydah Pirate Museum with documents that showed he was descended from Black Sam Bellamy. Scientists from the University of New Haven planned to test the bones for a DNA match with the descendant. \\n \\n Black Sam Bellamy left another legacy. Maria Hallett gave birth to Bellamy’s baby, who died. She spent a short time in jail. According to local lore, she lost her mind or became a recluse and moved to a shack in Wellfleet. She became known as ‘Goody Hallett’ or ‘The Witch of Wellfleet.’ Today a meadow in Wellfleet is known as Goody Hallett Meadow. \\n \\n With thanks to The Republic of Pirates: Being the True and Surprising Story of the Caribbean Pirates and the Man Who Brought Them Down by Colin Woodard. This story about Black Sam Bellamy was updated in 2018. ||||| Conservationists at the Whydah Pirate Museum said they found skeletal remains from the pirate ship Whydah Gally inside a mass of hardened sand and stone pulled from the wreck site near Wellfleet. \\n \\n Forget about pirate gold and silver. Researchers announced Wednesday they found real treasure: clues pulled from an 18th century shipwreck near Wellfleet that could reveal the fate of a legendary pirate captain. \\n \\n At the Whydah Pirate Museum in West Yarmouth, conservationists in November found part of the skeletal remains of a crew member of the Whydah Gally, a pirate ship that sank during a fierce nor’easter in 1717, said Chris Macort, an archeologist and director of the museum’s ship exhibit. \\n \\n “He walked among pirates and fought in the Caribbean,” Macort said. “It’s like walking through a history book.” \\n \\n Advertisement \\n \\n And there’s a chance these remains could be of pirate captain Samuel “Black Sam” Bellamy, an English sailor who had lived in Wellfleet, Macort said. \\n \\n Get Fast Forward in your inbox: Forget yesterday\\'s news. Get what you need today in this early-morning email. Sign Up Thank you for signing up! Sign up for more newsletters here \\n \\n Now Casey Sherman, who is creating a movie about finding the wreck, said he is helping the museum coordinate with forensic experts at the University of New Haven to compare DNA found in the remains with that of a known descendant of Bellamy living in England. \\n \\n “The Whydah site is the maritime equivalent of King Tut’s Tomb,” Sherman said in a statement released Wednesday. “Clifford and his divers continue to find Bellamy’s astounding treasure and now there’s a strong chance that we’ve located the remains of the Pirate Prince himself.” \\n \\n In a short, but successful, career, the Whydah Gally raided 54 ships along the eastern coast and in the Caribbean in 1716 and 1717, all under the command of Bellamy. \\n \\n In 2008, Forbes reported Bellamy had collected the equivalent of $120 million in wealth during his time as a pirate. \\n \\n Advertisement \\n \\n The bones will be displayed during a Feb. 19 press conference at the museum, Sherman said. \\n \\n Expedition Whydah Sea-Lab & Learning Center, Provincetown A drawing of the Whydah Gally \\n \\n The ship was originally built to carry slaves, and was armed with at least 60 cannons when it sank. Many of those weapons were found still fully loaded, he said. \\n \\n “Along with treasure and everything else, these guys were stealing cannons as well,” said Macort. “These guys were like the first Boy Scouts -- they were always prepared. They were always ready for battle.” \\n \\n When the ship went down, it took with it about four tons of pilfered silver and gold, and all but two of the 142-member crew, including Bellamy. It’s the only pirate ship found anywhere with its stolen treasure, said Macort. \\n \\n Experts have been trying to recover artifacts from the wreck since it was discovered by Barry Clifford and his diving team in 1984, said Macort. The museum opened its own doors in 2016 and allows visitors to watch conservationists at work, said Macort. \\n \\n Advertisement \\n \\n Clifford has recovered millions of dollars worth of treasure from the wreck site, according to Sherman’s statement. \\n \\n The human remains, plus what appear to be a pistol, cuff links, a belt, and other personal items, were encased in a 3,500-pound concretion -- essentially a mass of hardened sand and stone -- pulled from the wreck site several years ago. \\n \\n The concretion protected everything inside it over the centuries, until conservations recently began removing the material and discovered the bones, said Macort. \\n \\n Sherman said even if the remains are not those of Bellamy, he expects they will be interred. \\n \\n “This pirate has been at sea for 300 years. This is an opportunity to bring him home,” said Sherman in an interview. \\n \\n This is the second time researchers found human remains; in the early 1990s, a bone was found in the wreck they believed belonged to a young boy said to have sailed with Bellamy’s pirates, said Macort. \\n \\n “That was an incredible story no one knew about until we recovered his remains,” said Macort. \\n \\n The wreck site itself isn’t far from Cape Cod, but what’s left of the ship is under 20 feet of water, and another 20 feet of sand, he said, plus the spot is frequented by great white sharks. Archeologists visit every summer to recover more relics from the ship, and Macort expects they have years’ worth of work ahead of them. \\n \\n “The treasure for us is really uncovering the story of the Whydah,” said Macort. “It’s like a giant jigsaw puzzle, and in 30-odd years of working on the site, we have barely scratched the surface.” \\n \\n John Hilliard can be reached at john.hilliard@globe.com ||||| Starting in 1996, Alexa Internet has been donating their crawl data to the Internet Archive. Flowing in every day, these data are added to the Wayback Machine after an embargo period. ||||| Researchers hope to discover identity of mystery bone through DNA testing \\n \\n WEST YARMOUTH — A human bone recently discovered in a mass of hardened sediment that was pulled from the wreck of the Whydah pirate ship has sent researchers on a quest to learn more about the man to whom the bone belonged. \\n \\n The bone is beginning to protrude from a 3,500-pound rock-like concretion that now hangs suspended in an archaeological lab at the Whydah Pirate Museum where spectators can watch scientists work. \\n \\n Marie Kesten Zahn, archaeologist and conservator at the museum, has been slowly chipping away at the matter around the bone for about three weeks. \\n \\n \"I’m very excited to be finding something that could potentially tell us a lot of information,\" she said. \\n \\n An orthopedic surgeon who analyzed photos of the bone said it appears to be a broken femur that had begun to heal, indicating that the bone broke while the person was still alive, Kesten Zahn said. \\n \\n Photo Gallery: Archeologists at the Whydah Pirate Museum work to excavate bone \\n \\n Of the Whydah’s 146-man crew, two survived and 102 washed ashore, leaving 42 men unaccounted for, including the captain of the ship, Black Sam Bellamy, said Christopher Macort, an underwater field archaeologist with the museum. This bone must belong to one of those men, he said. \\n \\n With the help of forensic scientists, the researchers hope to find out exactly who he was, author Casey Sherman said. \\n \\n Sherman, a Cape native who co-authored \"The Finest Hours,\" a book and later a Disney movie about a 1952 Coast Guard rescue off the coast of Chatham, is partnering with undersea explorer Barry Clifford, who discovered the Whydah wreck, to investigate the bone and work on a feature film and possibly a reality TV show about Clifford’s search to uncover the Whydah’s mysteries. \\n \\n Sherman, who co-founded a production company called Whydah Productions, which was named for the sunken pirate ship long before Sherman’s partnership with Clifford, said Clifford’s story and the ever-unfolding mystery of the Whydah is prime material for entertainment. \\n \\n \"There’s history, there’s danger, there’s excitement, there’s adventure,\" he said. \"For me, it’s all about inspiration. How can somebody like (Clifford) inspire my readers? How can somebody like that inspire moviegoers or television viewers?\" \\n \\n Writers are working on a script for the movie, and Sherman said he is in touch with television production companies about a possible series, which likely would be a reality show based on the work of Clifford and his team. \\n \\n The discovery of the bone brings the storytelling potential to a new level, he said. \\n \\n \"It brings history alive,\" he said. \"If we can identify that this is any of the pirates, if we can identify that it’s Black Sam Bellamy, it’s akin to the discovery of King Tut’s tomb. It’s a huge piece of world history that should be developed and explained.\" \\n \\n For Sherman, who delved into forensic science and DNA analysis for his book \"A Rose for Mary,\" in which he investigated the Boston Strangler murders, the ultimate goal in studying the pirate bone is to match the DNA to a living descendant of one of the 42 lost pirates. \\n \\n The femur, which isn’t the first bone that archaeologists with the Whydah museum have found, brings the pirates to life for museum visitors as well, Macort said. \\n \\n The other bone discovered among the Whydah wreckage was the fibula of John King, an 8- to 11-year-old boy who ran away from home to join the pirates, he said. Archaeologists found the bone in 1989 inside a silk sock and next to a leather shoe, he said. \\n \\n The bone, sock and shoe are on display at the museum. \\n \\n \"Seeing these remains of the pirates actually brings that right back to life for us,\" he said. \"It’s sort of a grim reminder that these were real people. They died in a violent, terrible way.\" \\n \\n The state has regulations for reporting human remains found in Massachusetts waters. Remains must be reported to the chief medical examiner, who will determine the age of the remains, according to a policy from the state Board of Underwater Archaeological Resources. \\n \\n If the remains are less than 100 years old, a criminal investigation can be opened, according to the policy. If the remains are over 100 years old, the medical examiner must notify the state archaeologist who is tasked with determining the age, cultural affiliation and identity of the remains. If the remains are determined to be Native American, the Commission on Indian Affairs must be notified, according to the policy. \\n \\n The Whydah sank in 1717, so the bone is at least 300 years old. \\n \\n Macort said he reported the bone to Victor Mastone, director of the state Board of Underwater Archaeological Resources, with whom the Whydah archaeologists often work closely. Mastone is working in the field and can’t be reached until next week, according to a recorded message on his voicemail. \\n \\n Archaeologists could spend a year working to fully extract the bone and the dozens of other artifacts contained within the 3,500-pound mass, Macort said. \\n \\n But as researchers slowly chip away at the sediment around the pirate femur, Clifford said he will be chasing the answer to one question. \\n \\n \"Who was this man?\" he said. \\n \\n — Follow Madeleine List on Twitter: @madeleine_list. ||||| YARMOUTH, Mass. (AP) — Researchers are examining whether human bones found in a Cape Cod shipwreck are those of the infamous pirate Samuel \"Black Sam\" Bellamy. \\n \\n The Whydah Pirate Museum in Yarmouth, Massachusetts, says Wednesday that archeologists uncovered the remains in the wreck last year, near what they believe to be Bellamy\\'s pistol. \\n \\n They\\'ve enlisted forensic scientists from the University of New Haven in Connecticut to compare DNA from the bones to a DNA sample given by one of Bellamy\\'s living descendants in the United Kingdom. \\n \\n The Whydah Gally (WIH\\'-duh GAH\\'-lee) went down in stormy seas off Wellfleet in 1717, killing nearly all its 150-person crew, including Bellamy, and leaving its ill-gotten riches at the bottom of the ocean. \\n \\n It was discovered in 1984 by Barry Clifford, an explorer who owns the pirate museum.',\n",
       " 'summary': '– When the Whydah Gally went down in a 1717 storm 144 lives were lost—none so noteworthy as that of Samuel \"Black Sam\" Bellamy. The New England Historical Society describes the pirate as infamous, but not infamously cruel: As historian Colin Woodard puts it, he followed a credo of \"Fight smart, harm few, score big,\" and big he did score—plundering 54 ships before his watery death at age 28. The wreck of the Whydah Gally was found off Wellfleet, Mass., in 1984 by Barry Clifford, whose Whydah Pirate Museum now features coins, weapons, and other items pulled from the wreckage, with the Boston Globe reporting the ship also had four tons of silver and gold aboard. It notes a 2008 report from Forbes that weighed in on just how successful Bellamy was on the financial front: It estimated he had pilfered the equivalent of $120 million as a pirate. The museum earlier this month announced that archaeologists in 2017 located remains in a huge concretion (that is, a hardened mass of sand and stone) pulled from the wreck near what they suspect is Bellamy\\'s pistol, reports the AP. University of New Haven scientists now plan to compare whatever DNA they can recover from the femur with that of one of Bellamy\\'s modern-day relatives, with results due in roughly 6 weeks, reports the Cape Cod Times. If the bones are indeed Bellamy\\'s, they\\'ll be buried in his native England. As for his nickname, \"Black Sam\" came from the fact that declined to wear the powdered wigs popular in the day, instead simply securing his black hair with a black satin ribbon. (A surprising find was recently made in Blackbeard\\'s cannon.)'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Sample of validation data:')\n",
    "ds['validation'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and tokenized the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(col_name):\n",
    "    # Replace HTML tags with space\n",
    "    txt_clean = re.sub('<[^>]*>', ' ', col_name)\n",
    "\n",
    "    # Replace multiple spaces with a single space, leading and trailing space but keep line break '/n'\n",
    "    txt_clean = re.sub('[ \\t]+', ' ', txt_clean).strip()\n",
    "\n",
    "    return txt_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  set up max input and output length\n",
    "max_news_length=1024\n",
    "max_sum_length=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model evaluation metric\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and tokenized the dataset\n",
    "def preprocess(dataset):\n",
    "    # clean the input/document column of the dataset\n",
    "    document = [clean_txt(doc) for doc in dataset[\"document\"]]\n",
    "    \n",
    "    # tokenize news and summary\n",
    "    model_inputs = tokenizer(document,  truncation=True,max_length=max_news_length)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        summary = dataset[\"summary\"]\n",
    "        labels = tokenizer(summary,  truncation=True,max_length=max_sum_length )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66050fdca1d4989baa7468f2dd31b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44971 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79637cd40a06495eb05dfc9f676d536f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5621 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0500906fd34fb5b6475b593904eb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5621 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_token = ds.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up training arguments with adam optimiser only\n",
    "batch_size = 5\n",
    "epoch_size = 3\n",
    "save_limit_ct = 2\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"{model_name}{ver_}_results\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=epoch_size,\n",
    "    save_total_limit=save_limit_ct,\n",
    "    evaluation_strategy= 'epoch',\n",
    "    logging_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='rouge1',\n",
    "    greater_is_better=True,\n",
    "    predict_with_generate=True,\n",
    "    save_strategy='epoch',\n",
    "    #learning_rate=2e-5,\n",
    "    adam_beta1=0.8,\n",
    "    adam_beta2=0.98\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metrics evaluation function\n",
    "def metrics_eval(pred_eval):\n",
    "    predictions, labels = pred_eval\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    results = []\n",
    "    for pred, ref in zip(decoded_preds, decoded_labels):\n",
    "        result = scorer.score(ref, pred)\n",
    "        results.append(result)\n",
    "    \n",
    "    # Create a dictionary to store the metrics\n",
    "    metric_result = {}\n",
    "\n",
    "    for key in ['rouge1', 'rouge2', 'rougeL','rougeLsum']:\n",
    "        fmeasures = [result[key].fmeasure for result in results]\n",
    "        metric_result[key] = np.mean(fmeasures) * 100\n",
    "        \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    metric_result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return metric_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model and data collator from hugging face \n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=ds_token[\"train\"],\n",
    "    eval_dataset=ds_token[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator,\n",
    "    compute_metrics=metrics_eval\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of the process for t5-small_v4_adam_full: 2023-04-30 23:21:57.537737\n"
     ]
    }
   ],
   "source": [
    "#Start Time of training\n",
    "train_start_time = time.time()\n",
    "model_train_start = datetime.datetime.now()\n",
    "\n",
    "print(f\"Start of the process for {model_name}{ver_}:\", model_train_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba638f6a0cce47baa9288c25583240e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26985 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9039, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6145fa7793b44838ed7c91a3b05d8a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.604243278503418, 'eval_rouge1': 15.304385203029156, 'eval_rouge2': 5.063256517158665, 'eval_rougeL': 11.633600605333875, 'eval_rougeLsum': 13.476210661443966, 'eval_gen_len': 18.99679772282512, 'eval_runtime': 503.4263, 'eval_samples_per_second': 11.165, 'eval_steps_per_second': 2.235, 'epoch': 1.0}\n",
      "{'loss': 2.7971, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3400a4d69028427389d2a59bd494fd99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.570906639099121, 'eval_rouge1': 15.397529397842202, 'eval_rouge2': 5.026503644947118, 'eval_rougeL': 11.679998375354938, 'eval_rougeLsum': 13.54486799887717, 'eval_gen_len': 18.99679772282512, 'eval_runtime': 464.0004, 'eval_samples_per_second': 12.114, 'eval_steps_per_second': 2.425, 'epoch': 2.0}\n",
      "{'loss': 2.7646, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79af53aa85a2446bb258af5be2d26a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.563429832458496, 'eval_rouge1': 15.403717421340362, 'eval_rouge2': 5.040224350735755, 'eval_rougeL': 11.687637079151099, 'eval_rougeLsum': 13.561094246659152, 'eval_gen_len': 18.99679772282512, 'eval_runtime': 486.5382, 'eval_samples_per_second': 11.553, 'eval_steps_per_second': 2.312, 'epoch': 3.0}\n",
      "{'train_runtime': 11196.6178, 'train_samples_per_second': 12.049, 'train_steps_per_second': 2.41, 'train_loss': 2.821881079766537, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "trainer_output = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of the training with t5-small_v4_adam_full at 2023-05-01 02:28:34.313467...\n",
      "Total training time : 3.11 hours\n"
     ]
    }
   ],
   "source": [
    "model_train_end = datetime.datetime.now()\n",
    "print(f\"End of the training with {model_name}{ver_} at {model_train_end}...\")\n",
    "\n",
    "# Calculate the total training time\n",
    "train_end_time = time.time()\n",
    "training_time = train_end_time - train_start_time\n",
    "print(f\"Total training time : {training_time/3600:.2f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_rouge1</th>\n",
       "      <th>eval_rouge2</th>\n",
       "      <th>eval_rougeL</th>\n",
       "      <th>eval_rougeLsum</th>\n",
       "      <th>eval_gen_len</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.604243</td>\n",
       "      <td>15.304385</td>\n",
       "      <td>5.063257</td>\n",
       "      <td>11.633601</td>\n",
       "      <td>13.476211</td>\n",
       "      <td>18.996798</td>\n",
       "      <td>503.4263</td>\n",
       "      <td>11.165</td>\n",
       "      <td>2.235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.570907</td>\n",
       "      <td>15.397529</td>\n",
       "      <td>5.026504</td>\n",
       "      <td>11.679998</td>\n",
       "      <td>13.544868</td>\n",
       "      <td>18.996798</td>\n",
       "      <td>464.0004</td>\n",
       "      <td>12.114</td>\n",
       "      <td>2.425</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.563430</td>\n",
       "      <td>15.403717</td>\n",
       "      <td>5.040224</td>\n",
       "      <td>11.687637</td>\n",
       "      <td>13.561094</td>\n",
       "      <td>18.996798</td>\n",
       "      <td>486.5382</td>\n",
       "      <td>11.553</td>\n",
       "      <td>2.312</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eval_loss  eval_rouge1  eval_rouge2  eval_rougeL  eval_rougeLsum   \n",
       "0   2.604243    15.304385     5.063257    11.633601       13.476211  \\\n",
       "1   2.570907    15.397529     5.026504    11.679998       13.544868   \n",
       "2   2.563430    15.403717     5.040224    11.687637       13.561094   \n",
       "\n",
       "   eval_gen_len  eval_runtime  eval_samples_per_second  eval_steps_per_second   \n",
       "0     18.996798      503.4263                   11.165                  2.235  \\\n",
       "1     18.996798      464.0004                   12.114                  2.425   \n",
       "2     18.996798      486.5382                   11.553                  2.312   \n",
       "\n",
       "   epoch   step  \n",
       "0    1.0   8995  \n",
       "1    2.0  17990  \n",
       "2    3.0  26985  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_history = trainer.state.log_history\n",
    "df_log_history = pd.DataFrame([x for x in log_history if len(x)==11])\n",
    "df_log_history.to_csv('log_history.csv')\n",
    "df_log_history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the model back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint_path = trainer.state.best_model_checkpoint\n",
    "\n",
    "# Load the saved model from the output directory\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(best_checkpoint_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the 'Validation' dataset for brench marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb9cd0e5e154f20b232db5e9b3e30cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model on validation dataset\n",
    "validation_results = trainer.evaluate(ds_token[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_rouge1</th>\n",
       "      <th>eval_rouge2</th>\n",
       "      <th>eval_rougeL</th>\n",
       "      <th>eval_rougeLsum</th>\n",
       "      <th>eval_gen_len</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>2.589778</td>\n",
       "      <td>15.280849</td>\n",
       "      <td>5.072612</td>\n",
       "      <td>11.682255</td>\n",
       "      <td>13.458973</td>\n",
       "      <td>18.996798</td>\n",
       "      <td>477.7765</td>\n",
       "      <td>11.765</td>\n",
       "      <td>2.355</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eval_loss  eval_rouge1  eval_rouge2  eval_rougeL  eval_rougeLsum   \n",
       "value   2.589778    15.280849     5.072612    11.682255       13.458973  \\\n",
       "\n",
       "       eval_gen_len  eval_runtime  eval_samples_per_second   \n",
       "value     18.996798      477.7765                   11.765  \\\n",
       "\n",
       "       eval_steps_per_second  epoch  \n",
       "value                  2.355    3.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_results_df = pd.DataFrame.from_dict(validation_results, orient=\"index\", columns=[\"value\"]).transpose()\n",
    "validation_results_df.to_csv('validation_results.csv')\n",
    "validation_results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the model to validation records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: \n",
      " A President Of the Peephole \n",
      " \n",
      " \n",
      " \n",
      " By Carl Sferrazza Anthony \n",
      " \n",
      " Special to The Washington Post \n",
      " \n",
      " Sunday, June 7, 1998 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " F earing revelations about his illicit affair with a young campaign volunteer  which included sex in an Oval Office hideaway while under the guard of Secret Service agents  the president realized that stonewalling was ultimately futile. He stunned a private party of reporters at the National Press Club by confessing his carnal desires. \"It's a good thing I am not a woman,\" the president said. \"I would always be pregnant. I can't say no.\" In this administration, the scandals never seemed to end. There was the strange suicide of an administration official, made even more mysterious by a note that disappeared. Then came an investigation into payoffs and coverups connected to a notorious land deal. The president's friends launched smear campaigns against his perceived foes. Dossiers were compiled; private eyes and snitches deployed. Affidavits were drafted in which various women denied liaisons with the president. Jobs were arranged to keep people quiet. Through it all, a steel-willed first lady kept the press at bay and did whatever was necessary to defend her husband's reputation  even if it meant destroying evidence. The scandals erupted at a time when technological advances in communication were feeding a nation hungry for distraction, and the economy was booming. Sex sold  and the ravenous press corps was all too happy to name names and offer seamy details. The president and his wife boosted their public image by bringing Hollywood stars to the White House; they knew the value of glamour and the power of celebrity. It also helped that he was a genial populist and inveterate shaker of hands, fond of golf and cards, a man of the people. Ladies thought him virile and handsome; he photographed well. For some reason, all of this seems familiar. Whatever else may be said of Warren Gamaliel Harding  whose tenure as 29th president ended with his peculiar, premature death in 1923  he was a truly modern politician. His administration, which reeked of corruption, offers a prototype for Washington scandals. Whitewater, Iran-contra and Watergate are better known today, but the granddaddy of them all was Teapot Dome, a political maelstrom that broke 75 years ago this month and is still hard to top in terms of sheer outrageousness. Harding, a small-town Ohio newspaper publisher, was uniquely unsuited for the job of president  and he knew it. \"I am not fit for this office and never should have been here,\" he once said. But he \"looked like a president,\" as one major backer put it, and his wife, Florence, was instrumental in shepherding his political career. (The press considered Florence, known as the Duchess, to be the power behind the throne; one cartoon depicted the couple as \"The Chief Executive and Mr. Harding.\") Harding, a one-term Republican senator, won the job by promising Americans a \"return to normalcy\" after World War I. Though his legacy was soiled, his domestic achievements were substantial: the 40-hour work week, improved health care for new mothers, the first balanced-budget bureau, a focus on technology. And we have to give Harding credit for establishing a venerable institution: the Washington gossip mill. Based on new documentation, here's a reprise of the Harding era. I love your back, I love your breasts \n",
      " \n",
      " Darling to feel, where my face rests, \n",
      " \n",
      " I love your skin, so soft and white, \n",
      " \n",
      " So dear to feel and sweet to bite. . . . \n",
      " \n",
      " I love your poise of perfect thighs, \n",
      " \n",
      " When they hold me in paradise. . . . \n",
      " \n",
      "  A Harding poem to one of his mistresses, Carrie Phillips No president had more \"women scrapes,\" as his attorney general put it, than Warren G. His first affair, three years into his marriage to Florence, was with Susie Hodder  his wife's best friend from childhood  resulting in the birth of a daughter. His second affair was with Florence's closest adult friend, Carrie Fulton Phillips. It lasted 15 years. His third enduring mistress was his Senate aide, Grace Cross. Number four was the most infamous and the first presidential mistress to write a memoir: In the large Oval Office closet, the president had at least one tryst with Nan Britton, Britton went under covers with the president and wrote a memoir. (File Photo/Courtesy Library of Congress) \n",
      " \n",
      " a campaign volunteer who had started having sex with Harding when he was 51 and she was 22. Their assignations, facilitated by Secret Service agents James Sloan and Walter Ferguson (\"Harding hated to have them around, for he despised being watched,\" reported the chief usher), came to an abrupt stop when another agent, Harry Barker, tipped Florence off, and she ran down for a confrontation. It was in Harding's Senate office, late one night in the winter of 1919, that Britton claimed she conceived their daughter, Elizabeth Ann. They disrobed because Harding wanted to \"visualize\" her while he worked there during the day. Britton worried that they lacked the \"usual paraphernalia which we always took to the hotels . . . and of course, the Senate Offices do not provide preventive facilities for use in such emergencies.\" He had assorted other flings, including one with Rosa Hoyle, said to have conceived his only illegitimate son, and one with Augusta Cole, whose pregnancy by Harding was terminated. He bedded a Washington Post employee known as Miss Allicott, and former chorus girls Maize Haywood and Blossom Jones  all procured by Harding's crony, Washington Post publisher and owner Ned McLean. And then there's the string of \"New York women\"  including one who committed suicide after Harding wouldn't marry her, and another who had a stash of incriminating love letters purchased by Harding loyalists. The president even publicly ogled Margaret Gorman, the first Miss America, in Atlantic City, days after her crowning. Follow the Money Just weeks after his inauguration in 1921, Harding approved Interior Secretary Albert Fall's request to transfer oil reserves from the Navy Department to Fall's control. Fall then secretly leased the reserve at Elks Hills, Calif., to oilman Edward Doheny and the one at Teapot Dome, Wyo., to Harry Sinclair  in exchange for a \"loan\" of cash and stock worth nearly $400,000, delivered in a small black satchel, and a \"gift\" of $100,000 from Doheny. Fall became the first Cabinet member to be thrown in prison. Col. Charles Forbes, the first director of the U.S. Veterans Bureau, created by Harding, was particularly close to the first lady. She saw to his appointment, and entrusted him with $450 million to build hospitals and provide decent medical care for the thousands of disabled veterans of World War I, on whose behalf the Duchess was a national activist. Instead, he bilked tens of thousands out of building contractors and medical supply companies. He was eventually imprisoned  but not before Harding personally throttled him against the Red Room wall in the White House. Although Attorney General Harry Daugherty, a Harding crony and campaign manager, eluded conviction on a variety of pardon-selling and influence-peddling charges, his Justice Department was riddled with malfeasance, kickbacks and payoffs. One of the department's central tasks was to intimidate any Harding mistress who threatened the president with blackmail. High Officials Evalyn McLean, the Post publisher's wife, was a confidante of Mrs. Harding and an admitted intermittent morphine The president served liquor freely in the present-day Yellow Oval Room to his guests. addict. Despite Prohibition, she also was a heavy drinker and speakeasy regular  but then, so were her husband and other ranking government officials: Albert Fall, Col. Forbes and the president's chief aide, George Christian. In the Veterans Bureau, stories eventually broke about flapper secretaries and young officers having a regular cocktail hour, with shakers and glasses at the ready, overseen by Forbes. The president served liquor freely in the present-day Yellow Oval Room to his guests. Alice Longworth  a regular at poker  recalled that the first lady mixed the drinks. \"No rumor could have exceeded the truth. . . . [T]rays with bottles containing every imaginable brand of whiskey stood about,\" she remembered. And, according to recently declassified FBI reports, Harding was drunk on whiskey during an Oval Office confrontation with railroad union leaders during their 1922 strike. At the center of the capital's most elite bootlegging service was Jess Smith  who, even though never an employee or even a volunteer at the Justice Department, used official letterhead, cars and staff, and sat in on private meetings with FBI Director Billy Burns. Smith enjoyed these perks as the bachelor companion of the attorney general. Smith also served as the first lady's favorite escort and arbiter of her jaunty '20s fashions. Through the Justice Department, Smith had access to whiskey supplies confiscated by Prohibition agents, and some of the booze went directly to the White House, and to the McLeans, while the rest was kept for parties at the \"Love Nest,\" the small house shared by Smith and Daugherty, complete with a pink taffeta bedroom. Hollywood Values Working closely with Republican National Committee Chairman Will Hays during the 1920 campaign, Florence Harding conceived of recruiting Hollywood movie stars to support her husband. Al Jolson was drafted to head the Harding-Coolidge Theatrical League, and on Aug. 24, 1920, the marriage of politics and entertainment was forged forever when Jolson brought 40 movie stars to the Harding home for a campaign rally. The White House became a little Hollywood. On any given day, D.W. Griffith, the Gish sisters or Tom Mix might pose for newsreel cameras with the Hardings. When Hays left his job as postmaster general to become president of the Motion Picture Producers and Distributors of America, he developed a \"project to link the White House with the motion picture industry\" by providing a movie library. All of this was nothing short of immoral to old society. The religious press took even greater offense to Florence's ringing the stately halls with jazz for the first time. The Biblical Recorder excoriated the Hardings for \"setting a bad example by joining in the modern dance with its 'jazz' music.\" Squelching the Bimbos There was a good reason for Jess Smith having a vaguely defined association with the Justice Department. In this way, he was able to act at the implicit direction of the attorney general and FBI director and carry out a systematic intimidation of Harding mistresses who threatened to do as Carrie Phillips did and demand blackmail for their love Ned McLean ... did his utterly unethical best to destroy any anti-Harding efforts he heard about as publisher of The Post. letters. At one point, in exchange for apparently small amounts of money, affidavits disclaiming rumors of their liaisons were wrestled out of Evelyn Ruby, Augusta Cole and Cecilia Hoyle, and made their way to the first lady. In April 1921, Ned McLean officially became an agent of the FBI, and did his utterly unethical best to destroy any anti-Harding efforts he heard about as publisher of The Post. Such responsibilities included ripping the blouse of Nan Britton to try to snatch letters she claimed to be carrying  in the privacy of his editorial office. Even on the eve of his inauguration, Harding was providing more trouble for his troubleshooters. He had arranged a late-night rendezvous with Grace Cross, his Senate aide, in a Willard Hotel room. Some of his friends, recalled Olive Clapper, a reporter's wife, \"ordered her to pack and get out of town, threatening to put the FBI on her trail if she didn't go at once. She was so frightened she left immediately.\" Psychic Guidance Mrs. Harding's diary, discovered last year at an Ohio barn auction, revealed her to be a true believer in crystal ball readings, the zodiac and clairvoyance. In February 1920, as a Senate wife, she had her first consultation with capital society's seer, \"Madame Marcia.\" The psychic predicted that if Harding ran for president that year, he would be nominated  but that if he won the election, he would not live through his full term and instead die of \"sudden, peculiar, violent . . . death by poison.\" Knowing that the blackmail price of $25,000 demanded by Carrie Phillips for the love letters could never be met unless her husband became a presidential nominee, Florence pushed him through the primaries on to the nomination, ignoring the ominous prediction. During the Harding presidency, Madame Marcia was regularly fetched by the first lady's Secret Service agent, brought through the back entrance and escorted to the presidential bedroom for zodiac updates. Madame Marcia also did horoscopes for the president's public appearances; the first lady was trying to protect him from numerous assassination and bomb threats. When Florence got early inklings of the Teapot Dome, Veteran's Bureau and Justice Department scandals, she asked Marcia to do astrological charts of Cabinet members  and used the results as evidence to remove some of the crooks from the administration. Blackmailers' Delight Newly discovered documents now prove that Harding was the only president successfully blackmailed by a mistress. Once he was nominated as the Republican candidate, the national GOP committee paid off Carrie Phillips's lump-sum demand of $25,000 and monthly stipend of $2,000, funneled through a secret bank account kept, apparently, under Jess Smith's name (the records were burned by Attorney General Daugherty). Once Harding became president, Phillips returned from an all-expense-paid trip abroad and demanded that her brother and son-in-law be given federal posts. It was done. Harding even circulated the name of Phillips's husband to be ambassador to Japan  before word got out why he thought a dry-goods salesman from Marion, Ohio, deserved the post and the idea was quashed. One night, when he was a senator, Harding had such a row with aide Grace Cross that she cut his back and the police were called. Thereafter, Cross went around town talking about a \"birthmark\" on the president's back that she could identify  undoubtedly the wound  which became part of her arsenal in unsuccessful attempts to get blackmail money. However, former Democratic attorney general Mitchell Palmer would later use his knowledge of the Cross affair to force Harding to drop a Justice Department prosecution against him. Crossing a Friend After a failed attempt to frame Cross with a phony affidavit claiming she was a liar and blackmailer, Smith approached Bertha Martin  a friend of Cross's  to try to get possession of the aide's love letters from Harding. Martin said she would turn on her friend on the condition that she was given the job of society editor at The Post. Smith went to McLean, who gave his nod. Martin took Cross to lunch, asked to see the letters, snatched them away and bolted out of the restaurant. She was made society editor  and still managed to stay friends with Cross, taking her on a European vacation, courtesy of the secret blackmail fund. Deadly Sins During a party at Smith and Daugherty's \"Love Nest,\" some New York chorus girls were brought down to entertain a stag party. In attendance was the president. When glasses and bottles were being flung off the table so the dancing girls could perform, one Washington prostitute, identified only as a Miss Walsh, was knocked unconscious. Harding was hustled out. The woman died and was buried in a potter's field. In recently discovered transcripts of her taped revelations, Evalyn McLean recalled that the FBI director \"railroaded\" the woman's brother into St. Elizabeths mental hospital when he suggested a blackmail payment. Censorship by Book Burning \"The Strange Death of President Harding,\" written in 1930 by the notorious perjurer and former FBI agent Gaston Means, implied that Florence Harding poisoned her husband in retaliation for his adultery, but the book has long been dismissed as a fabrication. New evidence shows that while Means lied in details, he told general truths. He said that he was part of an FBI effort to seize and destroy a small, privately printed book, \"The Illustrated Life of Warren Gamaliel Harding,\" that revealed Harding's affair with Carrie Phillips, the RNC blackmail payoff and Florence's out-of-wedlock child by a common-law first husband. This turned out to be the only book suppressed by the government in peacetime. The entire action was illegal, and thus the boxes of books and updated manuscript inserts were taken not to any government property but to the McLean estate, where they were all burned. Well, not all: An original with the author's notes sits with none other than Evalyn McLean's papers at the Library of Congress. Spying Among Gaston Means's other sensational charges was that he spied for the first lady on Nan Britton. In fact, it was probably Grace Cross  for at least one letter sent to her from the president's office was purloined and found its way into the file on Cross in the McLeans' private papers. Post reporter Vylla Poe Wilson later admitted that both \"Mrs. Harding and Mrs. McLean were very jealous women, and they hired Gaston Means to follow Harding and McLean and report on their actions.\" In congressional hearings on the Justice Department, it was confirmed that Agent Means not only spied on Cross but the president's physician, Charles Sawyer, and his mistress, the first lady's housekeeper. Suicides Congress first heard tales of gross corruption at the Veterans Bureau in February 1923. Col. Forbes's colleague in kickbacks, Charles Cramer  the bureau's chief counsel, and the purchaser of the Hardings' Senate home  wrote out a letter to the president in his dining room, then stood before the bathroom mirror and shot himself. The letter mysteriously disappeared. At the start of the summer, the first big Harding scandal broke with the news that Jess Smith was found in his room with his head in a trash can, and a bullet in his head. The official word went out that it was a suicide due to health and emotional problems. Bertha Martin of The Post recalled that it was \"noised about\" town that Smith was a known homosexual, and that he was heartbroken over Daugherty's sudden rejection of his friendship when the president learned of Smith's nefarious activities. Others, like Evalyn McLean, simply believed Daugherty, Means or Burns had Smith killed because he knew too much. As for Martin, after a second career bootlegging whiskey to embassies, she was found dressed in her fur coat, pearls and white gloves with her head on the gas range, another alleged suicide. Negligent Homicide? Beginning on June 20, 1923, the Hardings sought to escape the heat and scandal of Washington on a 15,000-mile transcontinental train trip and voyage to Alaska. The president was 57 at the time. The recently unsealed diary and notes of naval physician Joel Boone reveal Boone's grave concerns about the president's heart condition. The warnings were ignored by longtime Harding homeopath \"Doc\" Sawyer, who made no effort to stop Harding from speaking in the blistering heat, driving the golden spike to complete the Alaska Railroad, or doing other arduous tasks. In this Sawyer had the absolute approval of the first lady, who was now enjoying the height of her national popularity and didn't want the trip canceled. She viewed the incompetent Sawyer as her own Rasputin, who'd miraculously kept a chronic kidney ailment from killing her. When Harding suffered a bout of food poisoning from tainted crab meat at Cordova, Alaska, Doc Sawyer ultimately weakened the president's sick heart by treating him with heavy doses of purgatives to flush out the toxins. On Aug. 2, 1923, when Boone was out of the sickroom in San Francisco's Palace Hotel, Sawyer plied one too many purgatives  in Florence's presence  and Harding died. There was a quick coverup regarding who was in the room and at precisely what time the president died. Mrs. Harding refused to permit an autopsy or a death mask, protecting her beloved Sawyer. \"Now that is all over,\" she told Evalyn McLean after Harding's death, \"I think it was all for the best.\" Evidence Destruction At the McLean estate, aptly named Friendship, Evalyn permitted the widowed first lady to bring from the White House wood crates full of government documents (which may have been incriminating to Harding) and helped burn them. Even though Mrs. Harding was being spied on and her phone was tapped during the congressional investigations of the scandals, she was able to keep destroying documents within the privacy of her Willard Hotel suite. Four months after leaving Washington, Florence died at age 64 in Marion, Ohio. She was staying in a cottage on the grounds of the Sawyer Sanitarium \"for the treatment of nervous and mental diseases,\" amid signs that read: \"Please do not stare at the Patients.\" This article is adapted from Carl Sferrazza Anthony's just-published biography, \"Florence Harding: The First Lady, the Jazz Age and the Death of America's Most Scandalous President\" (Morrow). ||||| Warren Harding's inauguration in 1921. (Photo: Unknown) \n",
      " \n",
      " Historians have long known that, before he became president, Warren G. Harding had an extramarital affair with a woman named Carrie Fulton Phillips. \n",
      " \n",
      " Soon, they'll be able to learn about it in more detail. \n",
      " \n",
      " The Library of Congress has announced that on July 29 it will release some 1,000 pages of love letters between Harding and Phillips, the wife of a friend. \n",
      " \n",
      " This was not Harding's most famous affair, it should be noted.That would be Nan Britton, who claimed that she carried on with Harding when he was president — once allegedly in a White House coat closet — and had his child. \n",
      " \n",
      " Britton's book, The President's Daughter, is considered the first kiss-and-tell book involving a president. \n",
      " \n",
      " Harding and Phillips began their affairs in 1905, but stopped before he became president in 1921. (Harding died in office in 1923.) \n",
      " \n",
      " The Library of Congress says most of the letters to be released were written between 1910 and 1920, including the years when Harding was a U.S. senator from Ohio. \n",
      " \n",
      " Phillips' lawyer and guardian found the letters after she died in 1960, but they were kept secret because of litigation. Harding's nephew, George Harding, eventually purchased the letters from a Phillips family member. \n",
      " \n",
      " Said the Library of Congress: \"In 1972, Dr. Harding donated the letters to the Library of Congress for safekeeping, with the stipulation that the Library keep the papers closed until July 29, 2014, which would be 50 years from the day the probate judge first closed them.\" \n",
      " \n",
      " Read or Share this story: http://usat.ly/1mkon7z\n"
     ]
    }
   ],
   "source": [
    "# Select input from DS\n",
    "nth = 5\n",
    "input_lab = 'document'\n",
    "output_lab = 'summary'\n",
    "sample_ds = ds['validation']\n",
    "\n",
    "print(f\"Input text: \\n {sample_ds[nth][input_lab]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target output of the sample document:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'– A thousand pages of love letters from the man some historians say was America\\'s most scandalous president to a mistress will see the light of day next month for the first time in around a century. The Library of Congress says the letters from Warren G. Harding to Claire Phillips, a friend of his wife\\'s, will be released when the 50-year period of secrecy the president\\'s nephew insisted on when he donated the letters expires, USA Today reports. The affair began in 1905, carried on throughout the years the Republican was a US senator from Ohio, and ended soon before he was elected in 1920. She successfully blackmailed the GOP over the affair, winning a monthly stipend and jobs for several relatives. But Phillips wasn\\'t the most famous mistress of Harding, who died in office in 1923. That distinction goes to young campaign volunteer Nan Britton, who claimed in 1928 tell-all book The President\\'s Daughter that they had sex in locations including a White House coat closet—and he fathered her child. According to a Washington Post profile, Harding had at least two other long-term mistresses, and had \"assorted other flings,\" including with \"a Washington Post employee known as Miss Allicott, and former chorus girls Maize Haywood and Blossom Jones,\" as well as \"a string of \\'New York women.\\'\" Harding \"even publicly ogled Margaret Gorman, the first Miss America, in Atlantic City, days after her crowning,\" the Post finds.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Target output of the sample document:')\n",
    "sample_ds[nth][output_lab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5577 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output of the sample document:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"– Warren Harding's affair with a woman has been a sl\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the custom input\n",
    "input_text = sample_ds[nth][input_lab]\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Move the input tensors to the same device as the model\n",
    "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "# Generate the summary\n",
    "summary1_ids = model.generate(**inputs)\n",
    "summary1 = tokenizer.decode(summary1_ids[0], truncation=True, skip_special_tokens=True,max_length=max_news_length)\n",
    "\n",
    "print('Model output of the sample document:')\n",
    "summary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input: n      \n",
      "    predictions: The system stream (a sequence of segments).\n",
      "    references: A list of one or more reference streams (each a sequence of segments).\n",
      "    smooth_method: The smoothing method to use. (Default: 'exp').\n",
      "    smooth_value: The smoothing value. Only valid for 'floor' and 'add-k'. (Defaults: floor: 0.1, add-k: 1).\n",
      "    tokenize: Tokenization method to use for BLEU. If not provided, defaults to 'zh' for Chinese, 'ja-mecab' for Japanese and '13a' (mteval) otherwise.\n",
      "    lowercase: Lowercase the data. If True, enables case-insensitivity. (Default: False).\n",
      "    force: Insist that your tokenized input is actually detokenized.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Manual Input\n",
    "input_text = \"\"\"\n",
    "    predictions: The system stream (a sequence of segments).\n",
    "    references: A list of one or more reference streams (each a sequence of segments).\n",
    "    smooth_method: The smoothing method to use. (Default: 'exp').\n",
    "    smooth_value: The smoothing value. Only valid for 'floor' and 'add-k'. (Defaults: floor: 0.1, add-k: 1).\n",
    "    tokenize: Tokenization method to use for BLEU. If not provided, defaults to 'zh' for Chinese, 'ja-mecab' for Japanese and '13a' (mteval) otherwise.\n",
    "    lowercase: Lowercase the data. If True, enables case-insensitivity. (Default: False).\n",
    "    force: Insist that your tokenized input is actually detokenized.\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(clean_txt(input_text), return_tensors=\"pt\")\n",
    "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "summary2_ids = model.generate(**inputs)\n",
    "summary2 = tokenizer.decode(summary2_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(f'Model input: n\\\n",
    "      {input_text}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:       – The system stream is a sequence of segments, and references: A list of one\n"
     ]
    }
   ],
   "source": [
    "print(f'Model output: \\\n",
    "      {summary2}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ANLP36118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
